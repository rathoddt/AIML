{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19fe218-8272-4a78-95dc-b45c7944d26d",
   "metadata": {},
   "source": [
    "# Building and deploying machine learning solutions with Vertex AI: Challenge Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e5394-d8e8-4b56-99a1-f7c3b0f574f4",
   "metadata": {},
   "source": [
    "This Challenge Lab is recommended for students who have enrolled in the [**Building and deploying machine learning solutions with Vertex AI**](https://www.cloudskillsboost.google/course_templates/684). You will be given a scenario and a set of tasks. Instead of following step-by-step instructions, you will use the skills learned from the labs in the quest to figure out how to complete the tasks on your own! An automated scoring system (shown on the Qwiklabs lab instructions page) will provide feedback on whether you have completed your tasks correctly.\n",
    "\n",
    "When you take a Challenge Lab, you will not be taught Google Cloud concepts. To build the solution to the challenge presented, use skills learned from the labs in the Quest this challenge lab is part of. You are expected to extend your learned skills and complete all the **`TODO:`** comments in this notebook.\n",
    "\n",
    "Are you ready for the challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908fb9b-2048-48fc-a42c-2fdf76aea51e",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbdce5-4287-4740-bdbd-729d15d8ab7f",
   "metadata": {},
   "source": [
    "You were recently hired as a Machine Learning Engineer at a startup movie review website. Your manager has tasked you with building a machine learning model to classify the sentiment of user movie reviews as positive or negative. These predictions will be used as an input in downstream movie rating systems and to surface top supportive and critical reviews on the movie website application. The challenge: your business requirements are that you have just 6 weeks to productionize a model that achieves great than 75% accuracy to improve upon an existing bootstrapped solution. Furthermore, after doing some exploratory analysis in your startup's data warehouse, you found that you only have a small dataset of 50k text reviews to build a higher performing solution.\n",
    "\n",
    "To build and deploy a high performance machine learning model with limited data quickly, you will walk through training and deploying a custom TensorFlow BERT sentiment classifier for online predictions on Google Cloud's [Vertex AI](https://cloud.google.com/vertex-ai) platform. Vertex AI is Google Cloud's next generation machine learning development platform where you can leverage the latest ML pre-built components and AutoML to significantly enhance your development productivity, scale your workflow and decision making with your data, and accelerate time to value.\n",
    "\n",
    "![Vertex AI: Challenge Lab](./images/vertex-challenge-lab.png \"Vertex Challenge Lab\")\n",
    "\n",
    "First, you will progress through a typical experimentation workflow where you will build your model from pre-trained BERT components from TF-Hub and `tf.keras` classification layers to train and evaluate your model in a Vertex Notebook. You will then package your model code into a Docker container to train on Google Cloud's Vertex AI. Lastly, you will define and run a Kubeflow Pipeline on Vertex Pipelines that trains and deploys your model to a Vertex Endpoint that you will query for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955d75d-cfa4-43af-8783-d2aec5ae525e",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386b37c-2ce1-4b1f-8c90-b83bda6075c8",
   "metadata": {},
   "source": [
    "* Train a TensorFlow model locally in a hosted [**Vertex Notebook**](https://cloud.google.com/vertex-ai/docs/general/notebooks?hl=sv).\n",
    "* Containerize your training code with [**Cloud Build**](https://cloud.google.com/build) and push it to [**Google Cloud Artifact Registry**](https://cloud.google.com/artifact-registry).\n",
    "* Define a pipeline using the [**Kubeflow Pipelines (KFP) V2 SDK**](https://www.kubeflow.org/docs/components/pipelines/sdk/v2/v2-compatibility) to train and deploy your model on [**Vertex Pipelines**](https://cloud.google.com/vertex-ai/docs/pipelines).\n",
    "* Query your model on a [**Vertex Endpoint**](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) using online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23538a-e809-4747-9bd4-5610f8544ea1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d871a2",
   "metadata": {},
   "source": [
    "**NOTE: Make sure you have installed the required packages for the lab as specified in the Task 2 > step 3 of the lab instructions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04a090",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81be8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==3.25.0\n",
      "  Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in ./.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery==3.25.0) (2.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (2.40.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (2.7.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in ./.local/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (21.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.25.0) (2.32.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in ./.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery==3.25.0) (1.58.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery==3.25.0) (3.20.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery==3.25.0) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in ./.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery==3.25.0) (1.47.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery==3.25.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery==3.25.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery==3.25.0) (4.9.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==3.25.0) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery==3.25.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.25.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.25.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.25.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery==3.25.0) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery==3.25.0) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0.0->google-cloud-bigquery==3.25.0) (3.2.3)\n",
      "Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
      "Installing collected packages: google-cloud-bigquery\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.4.2\n",
      "    Uninstalling google-cloud-bigquery-3.4.2:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.11.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.11.0 requires google-cloud-resource-manager>=1.10.3, but you have google-cloud-resource-manager 1.8.1 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires packaging>=22.0.0, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-cloud-bigquery-3.25.0\n",
      "Collecting google-cloud-aiplatform==1.59.0\n",
      "  Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in ./.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (2.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (2.7.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (1.8.1)\n",
      "Requirement already satisfied: shapely<3.0.0dev in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (1.8.5.post1)\n",
      "Requirement already satisfied: pydantic<3 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (1.10.22)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.59.0) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in ./.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (1.58.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in ./.local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (1.47.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.59.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.59.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.59.0) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.59.0) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.59.0) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.59.0) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.59.0) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.59.0) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.59.0) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.59.0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.59.0) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.59.0) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.59.0) (3.2.3)\n",
      "Downloading google_cloud_aiplatform-1.59.0-py2.py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.22.0\n",
      "    Uninstalling google-cloud-aiplatform-1.22.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.22.0\n",
      "Successfully installed google-cloud-aiplatform-1.103.0\n",
      "Found existing installation: Shapely 1.8.5.post1\n",
      "Uninstalling Shapely-1.8.5.post1:\n",
      "  Successfully uninstalled Shapely-1.8.5.post1\n",
      "\u001b[33mWARNING: Skipping pygeos as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: geopandas 1.1.1\n",
      "Uninstalling geopandas-1.1.1:\n",
      "  Successfully uninstalled geopandas-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.11.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.11.0 requires google-cloud-resource-manager>=1.10.3, but you have google-cloud-resource-manager 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting pydot\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from pydot) (3.2.3)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-4.0.1\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fonts-liberation libann0 libcdt5 libcgraph6 libgts-0.7-5 libgts-bin libgvc6\n",
      "  libgvpr2 liblab-gamut1 libpathplan4\n",
      "Suggested packages:\n",
      "  gsfonts graphviz-doc\n",
      "The following NEW packages will be installed:\n",
      "  fonts-liberation graphviz libann0 libcdt5 libcgraph6 libgts-0.7-5 libgts-bin\n",
      "  libgvc6 libgvpr2 liblab-gamut1 libpathplan4\n",
      "0 upgraded, 11 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 3034 kB of archives.\n",
      "After this operation, 11.5 MB of additional disk space will be used.\n",
      "Get:1 https://deb.debian.org/debian bullseye/main amd64 fonts-liberation all 1:1.07.4-11 [828 kB]\n",
      "Get:2 https://deb.debian.org/debian bullseye/main amd64 libann0 amd64 1.1.2+doc-7 [25.3 kB]\n",
      "Get:3 https://deb.debian.org/debian bullseye/main amd64 libcdt5 amd64 2.42.2-5+deb11u1 [62.2 kB]\n",
      "Get:4 https://deb.debian.org/debian bullseye/main amd64 libcgraph6 amd64 2.42.2-5+deb11u1 [85.5 kB]\n",
      "Get:5 https://deb.debian.org/debian bullseye/main amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4+b1 [158 kB]\n",
      "Get:6 https://deb.debian.org/debian bullseye/main amd64 libpathplan4 amd64 2.42.2-5+deb11u1 [64.3 kB]\n",
      "Get:7 https://deb.debian.org/debian bullseye/main amd64 libgvc6 amd64 2.42.2-5+deb11u1 [695 kB]\n",
      "Get:8 https://deb.debian.org/debian bullseye/main amd64 libgvpr2 amd64 2.42.2-5+deb11u1 [212 kB]\n",
      "Get:9 https://deb.debian.org/debian bullseye/main amd64 liblab-gamut1 amd64 2.42.2-5+deb11u1 [221 kB]\n",
      "Get:10 https://deb.debian.org/debian bullseye/main amd64 graphviz amd64 2.42.2-5+deb11u1 [632 kB]\n",
      "Get:11 https://deb.debian.org/debian bullseye/main amd64 libgts-bin amd64 0.7.6+darcs121130-4+b1 [50.3 kB]\n",
      "Fetched 3034 kB in 0s (17.2 MB/s)       \u001b[0m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package fonts-liberation.\n",
      "(Reading database ... 142940 files and directories currently installed.)\n",
      "Preparing to unpack .../00-fonts-liberation_1%3a1.07.4-11_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking fonts-liberation (1:1.07.4-11) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package libann0.\n",
      "Preparing to unpack .../01-libann0_1.1.2+doc-7_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libann0 (1.1.2+doc-7) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libcdt5:amd64.\n",
      "Preparing to unpack .../02-libcdt5_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking libcdt5:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libcgraph6:amd64.\n",
      "Preparing to unpack .../03-libcgraph6_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libcgraph6:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libgts-0.7-5:amd64.\n",
      "Preparing to unpack .../04-libgts-0.7-5_0.7.6+darcs121130-4+b1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4+b1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libpathplan4:amd64.\n",
      "Preparing to unpack .../05-libpathplan4_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libpathplan4:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package libgvc6.\n",
      "Preparing to unpack .../06-libgvc6_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libgvc6 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libgvpr2:amd64.\n",
      "Preparing to unpack .../07-libgvpr2_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libgvpr2:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package liblab-gamut1:amd64.\n",
      "Preparing to unpack .../08-liblab-gamut1_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking liblab-gamut1:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package graphviz.\n",
      "Preparing to unpack .../09-graphviz_2.42.2-5+deb11u1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking graphviz (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package libgts-bin.\n",
      "Preparing to unpack .../10-libgts-bin_0.7.6+darcs121130-4+b1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking libgts-bin (0.7.6+darcs121130-4+b1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up liblab-gamut1:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4+b1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libpathplan4:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up libann0 (1.1.2+doc-7) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up fonts-liberation (1:1.07.4-11) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libcdt5:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libcgraph6:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up libgts-bin (0.7.6+darcs121130-4+b1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libgvc6 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up libgvpr2:amd64 (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up graphviz (2.42.2-5+deb11u1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for libc-bin (2.31-13+deb11u13) ...\n",
      "ldconfig: /lib/libnvinfer_vc_plugin.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvonnxparser.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvinfer_plugin.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvinfer.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvparsers.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvinfer_lean.so.8 is not a symbolic link\n",
      "\n",
      "ldconfig: /lib/libnvinfer_dispatch.so.8 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.9.4-2) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!pip3 install google-cloud-bigquery==3.25.0 -U\n",
    "!pip install google-cloud-aiplatform==1.59.0\n",
    "!pip uninstall -y shapely pygeos geopandas\n",
    "!pip install shapely==1.8.5.post1 pygeos==0.12.0 geopandas>=0.12.2\n",
    "# Install pydot and graphviz\n",
    "!pip install pydot\n",
    "!sudo apt install graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f3796",
   "metadata": {},
   "source": [
    "### After installing these packages you'll need to restart the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06064f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37a668",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ab494b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "# Add installed library dependencies to Python PATH variable.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68df5dd-c456-4edd-8f58-71597f10c0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve and set PROJECT_ID and REGION environment variables.\n",
    "# TODO: Fill in the PROJECT_ID and REGION provided in the lab manual.\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-af04a453fada\"\n",
    "REGION = \"us-central1\"\n",
    "GCS_BUCKET = f\"gs://{PROJECT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4931ae91-3ba1-437a-9c37-187a41a3d227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-02-af04a453fada/...\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage buckets create -l $REGION $GCS_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebbc2b-21ad-47f0-829f-9beba0deba9d",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf558fc-d0fc-4452-8281-7d7cd0cffe50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 05:26:40.501923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "# TensorFlow model building libraries.\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Re-create the AdamW optimizer used in the original BERT paper.\n",
    "from official.nlp import optimization  \n",
    "\n",
    "# Libraries for data and plot model training metrics.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Vertex AI Python SDK.\n",
    "from google.cloud import aiplatform as vertexai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296167a-13b9-4895-be8b-b3b49fad5d47",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c178b0-0edb-4e4b-abb4-d3cc0bd676de",
   "metadata": {},
   "source": [
    "Initialize the Vertex AI Python SDK with your GCP Project, Region, and Google Cloud Storage Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a43371e-2c64-4a76-8698-fa768043dbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2917411-811c-46dd-8eda-e8ef579c568d",
   "metadata": {},
   "source": [
    "## Build and train your model locally in a Vertex Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc8cc5-ed5e-457a-b5f5-475bacca4611",
   "metadata": {},
   "source": [
    "Note: this lab adapts and extends the official [TensorFlow BERT text classification tutorial](https://www.tensorflow.org/text/tutorials/classify_text_with_bert#define_your_model) to utilize Vertex AI services. See the tutorial for additional coverage on fine-tuning BERT models using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338a818-18e5-4b0b-b37d-b387577a08ef",
   "metadata": {},
   "source": [
    "### Lab dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfb91d-6060-4d00-a1c3-299ee6027b76",
   "metadata": {},
   "source": [
    "In this lab, you will use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment) that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews. Data ingestion and processing code has been provided for you below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef491df4-c35f-4555-a6b6-96114c3d3c6e",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee70d2c-c0e3-4c75-9bc6-b42dad6c7267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "LOCAL_DATA_DIR = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c889f275-ce52-4108-9f7f-7cf824184f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_data(data_url, local_data_dir):\n",
    "    \"\"\"Download dataset.\n",
    "    Args:\n",
    "      data_url(str): Source data URL path.\n",
    "      local_data_dir(str): Local data download directory path.\n",
    "    Returns:\n",
    "      dataset_dir(str): Local unpacked data directory path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.makedirs(local_data_dir)\n",
    "    \n",
    "    dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb_v1.tar.gz\",\n",
    "      origin=data_url,\n",
    "      untar=True,\n",
    "      cache_dir=local_data_dir,\n",
    "      cache_subdir=\"\")\n",
    "    \n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, \"train\")\n",
    "    \n",
    "    # Remove unused folders to make it easier to load the data.\n",
    "    remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "    shutil.rmtree(remove_dir)\n",
    "    \n",
    "    return dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f906a4-64a0-45ae-b376-757ef0f661fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = download_data(data_url=DATA_URL, local_data_dir=LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95a61fa-cf55-470f-9837-c783c4bcccf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to iteratively add data pipeline and model training hyperparameters.\n",
    "HPARAMS = {\n",
    "    # Set a random sampling seed to prevent data leakage in data splits from files.\n",
    "    \"seed\": 42,\n",
    "    # Number of training and inference examples.\n",
    "    \"batch-size\": 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aeea425-d288-44a7-9958-f2b1f48f9c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_datasets(dataset_dir, hparams):\n",
    "    \"\"\"Load pre-split tf.datasets.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      raw_train_ds(tf.dataset): Train split dataset (20k examples).\n",
    "      raw_val_ds(tf.dataset): Validation split dataset (5k examples).\n",
    "      raw_test_ds(tf.dataset): Test split dataset (25k examples).\n",
    "    \"\"\"    \n",
    "\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=hparams['seed'])    \n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=hparams['seed'])\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'test'),\n",
    "        batch_size=hparams['batch-size'])\n",
    "    \n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ff05aa4-d299-4c80-a29a-43c6bc3ac152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(DATASET_DIR, HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ee40c0-9e37-483c-98f5-dcdb467a2bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "CLASS_NAMES = raw_train_ds.class_names\n",
    "\n",
    "train_ds = raw_train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = raw_val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = raw_test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5734e-d97c-484d-9f52-f6fb4e153ef0",
   "metadata": {},
   "source": [
    "Let's print a few example reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d794068-817c-4cb8-8e4c-c49860d0c92d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      "Label : 0 (neg)\n",
      "Review 1: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      "Label : 0 (neg)\n",
      "Review 2: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
      "Label : 1 (pos)\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review {i}: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({CLASS_NAMES[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e6686-2fa1-453c-8259-8e5a87cba023",
   "metadata": {},
   "source": [
    "### Choose a pre-trained BERT model to fine-tune for higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502ad71-5747-4a11-9122-0b5c7b2049cd",
   "metadata": {},
   "source": [
    "[**Bidirectional Encoder Representations from Transformers (BERT)**](https://arxiv.org/abs/1810.04805v2) is a transformer-based text representation model pre-trained on massive datasets (3+ billion words) that can be fine-tuned for state-of-the art results on many natural language processing (NLP) tasks. Since release in 2018 by Google researchers, its has transformed the field of NLP research and come to form a core part of significant improvements to [Google Search](https://www.blog.google/products/search/search-language-understanding-bert). \n",
    "\n",
    "To meet your business requirements of achieving higher accuracy on a small dataset (20k training examples), you will use a technique called transfer learning to combine a pre-trained BERT encoder and classification layers to fine tune a new higher performing model for binary sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd347cc-5f87-4b89-8833-6df850729ec3",
   "metadata": {},
   "source": [
    "For this lab, you will use a smaller BERT model that trades some accuracy for faster training times.\n",
    "\n",
    "The Small BERT models are instances of the original BERT architecture with a smaller number L of layers (i.e., residual blocks) combined with a smaller hidden size H and a matching smaller number A of attention heads, as published by\n",
    "\n",
    "Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova: [\"Well-Read Students Learn Better: On the Importance of Pre-training Compact Models\"](https://arxiv.org/abs/1908.08962), 2019.\n",
    "\n",
    "They have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
    "\n",
    "The following preprocessing and encoder models in the TensorFlow 2 SavedModel format use the implementation of BERT from the [TensorFlow Models Github repository](https://github.com/tensorflow/models/tree/master/official/nlp/bert) with the trained weights released by the authors of Small BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22196658-1c30-49c7-8485-5d933fc8988e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HPARAMS.update({\n",
    "    # TF Hub BERT modules.\n",
    "    \"tfhub-bert-preprocessor\": \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    \"tfhub-bert-encoder\": \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50b93a-df95-47d9-bc14-14502ae4eb54",
   "metadata": {},
   "source": [
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. Since this text preprocessor is a TensorFlow model, It can be included in your model directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e50df-9d35-4116-a167-8353046bf6b9",
   "metadata": {},
   "source": [
    "For fine-tuning, you will use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26396cb1-fc24-4e96-bef2-6fc8e2d500a6",
   "metadata": {},
   "source": [
    "For the learning rate `initial-learning-rate`, you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps `n_warmup_steps`. In line with the BERT paper, the initial learning rate is smaller for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b634139-a0d1-41e7-be23-c6e580a4f0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HPARAMS.update({\n",
    "    # Model training hyperparameters for fine tuning and regularization.\n",
    "    \"epochs\": 2,\n",
    "    \"initial-learning-rate\": 3e-5,\n",
    "    \"dropout\": 0.1 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e415aeb-5ab2-42ac-904a-ae0649d45a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = HPARAMS['epochs']\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "n_train_steps = steps_per_epoch * epochs\n",
    "n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "\n",
    "OPTIMIZER = optimization.create_optimizer(init_lr=HPARAMS['initial-learning-rate'],\n",
    "                                          num_train_steps=n_train_steps,\n",
    "                                          num_warmup_steps=n_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b4646-ce95-47c4-b1f7-886f59980386",
   "metadata": {},
   "source": [
    "### Build and compile a TensorFlow BERT sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00169dd-8cea-47ec-ac9b-a41f70458a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HPARAMS.update({\n",
    "    \"epochs\": 2,\n",
    "    \"initial-learning-rate\": 3e-5,\n",
    "    \"dropout\": 0.1,\n",
    "    \"preprocessing_url\": \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    \"encoder_url\": \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80920377-4596-4dbd-8eb7-8580327fdb24",
   "metadata": {},
   "source": [
    "Next, you will define and compile your model by assembling pre-built TF-Hub components and tf.keras layers.\n",
    "\n",
    "**Note:** For any help while defining the model, you can refer [**TensorFlow BERT text classification tutorial**](https://www.tensorflow.org/text/tutorials/classify_text_with_bert#define_your_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289da96f-2aad-4c34-85ce-5916ea98778e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_text_classifier(hparams, optimizer):\n",
    "    \"\"\"Define and compile a TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      model(tf.keras.Model): A compiled TensorFlow model.\n",
    "    \"\"\"\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    # f: Add a hub.KerasLayer for BERT text preprocessing using the hparams dict. \n",
    "    # Name the layer 'preprocessing' and store in the variable 'preprocessor'.\n",
    "    preprocessor = hub.KerasLayer(\n",
    "    hparams['preprocessing_url'],\n",
    "    trainable=False,\n",
    "    name='preprocessing')\n",
    "    #preprocessor = hub.KerasLayer( hparams['preprocessing_url'], name='preprocessing')\n",
    "    \n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    # TODO: Add a trainable hub.KerasLayer for BERT text encoding using the hparams dict.\n",
    "    # Name the layer 'BERT_encoder' and store in the variable 'encoder'.\n",
    "    encoder = hub.KerasLayer(\n",
    "        hparams['encoder_url'], trainable=True, name='BERT_encoder'\n",
    "    )\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    # For the fine-tuning you are going to use the `pooled_output` array which represents \n",
    "    # each input sequence as a whole. The shape is [batch_size, H]. \n",
    "    # You can think of this as an embedding for the entire movie review.\n",
    "    classifier = outputs['pooled_output']\n",
    "    # Add dropout to prevent overfitting during model fine-tuning.\n",
    "    classifier = tf.keras.layers.Dropout(hparams['dropout'], name='dropout')(classifier)\n",
    "    classifier = tf.keras.layers.Dense(1, activation=None, name='classifier')(classifier)\n",
    "    model = tf.keras.Model(text_input, classifier, name='bert-sentiment-classifier')\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()    \n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036b72cc-9e1c-49c9-8a90-7b09b6108f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_text_classifier(HPARAMS, OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8198df2-c15a-4f79-a154-83c941aba5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize your fine-tuned BERT sentiment classifier.\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acfeb71d-4e19-4759-8f5c-293c8c7cee1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_REVIEW = ['this is such an amazing movie!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c2112f-9f04-470e-8636-38ea948cba9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.9770013]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "BERT_RAW_RESULT = model(tf.constant(TEST_REVIEW))\n",
    "print(BERT_RAW_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53dd9fa-d0a4-46ab-a123-3065b8fde7c8",
   "metadata": {},
   "source": [
    "### Train and evaluate your BERT sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f008fc-f696-4b71-9011-2a897d268795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HPARAMS.update({\n",
    "#     # TODO: Save your BERT sentiment classifier locally in the form of <key>:<path to save the model>. \n",
    "#     # Hint: You can use the key as 'model-dir' and save it to './bert-sentiment-classifier-local'.\n",
    "    \n",
    "# })\n",
    "HPARAMS.update({\n",
    "    # Model training hyperparameters for fine tuning and regularization.\n",
    "    \"epochs\": 2,\n",
    "    \"initial-learning-rate\": 3e-5,\n",
    "    \"dropout\": 0.1,\n",
    "\n",
    "    # URLs for preprocessing and encoder layers.\n",
    "    \"preprocessing_url\": \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    \"encoder_url\": \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",\n",
    "\n",
    "    # TODO completed: Save your BERT sentiment classifier locally.\n",
    "    \"model-dir\": \"./bert-sentiment-classifier-local\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd08f3-988f-408a-b694-af4702de85ba",
   "metadata": {},
   "source": [
    "**Note:** training your model locally will take about 10-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24660956-d60a-4c25-a654-7b192a01a2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_evaluate(hparams):\n",
    "    \"\"\"Train and evaluate TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    # dataset_dir = download_data(data_url, local_data_dir)\n",
    "    raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(DATASET_DIR, hparams)\n",
    "    \n",
    "    train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)     \n",
    "    \n",
    "    epochs = hparams['epochs']\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    n_train_steps = steps_per_epoch * epochs\n",
    "    n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "    \n",
    "    optimizer = optimization.create_optimizer(init_lr=hparams['initial-learning-rate'],\n",
    "                                              num_train_steps=n_train_steps,\n",
    "                                              num_warmup_steps=n_warmup_steps,\n",
    "                                              optimizer_type='adamw')    \n",
    "    \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_text_classifier(hparams=hparams, optimizer=optimizer)\n",
    "    \n",
    "    logging.info(model.summary())\n",
    "        \n",
    "    history = model.fit(x=train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=epochs)  \n",
    "    \n",
    "    logging.info(\"Test accuracy: %s\", model.evaluate(test_ds))\n",
    "\n",
    "    # Export Keras model in TensorFlow SavedModel format.\n",
    "    model.save(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549e700-bf6a-415a-bb35-01150d9535e5",
   "metadata": {},
   "source": [
    "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cab23-fbf0-44d2-9ee0-e2dd83390fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert-sentiment-classifier\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text (InputLayer)           [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)  {'input_mask': (None, 128)   0         ['text[0][0]']                \n",
      "                             , 'input_word_ids': (None,                                           \n",
      "                              128),                                                               \n",
      "                              'input_type_ids': (None,                                            \n",
      "                             128)}                                                                \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)   {'pooled_output': (None, 7   1094822   ['preprocessing[0][0]',       \n",
      "                             68),                         41         'preprocessing[0][1]',       \n",
      "                              'sequence_output': (None,              'preprocessing[0][2]']       \n",
      "                              None, 768),                                                         \n",
      "                              'default': (None, 768),                                             \n",
      "                              'encoder_outputs': [(None                                           \n",
      "                             , None, 768),                                                        \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768),                                                  \n",
      "                              (None, None, 768)]}                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 768)                  0         ['BERT_encoder[0][13]']       \n",
      "                                                                                                  \n",
      " classifier (Dense)          (None, 1)                    769       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109483010 (417.64 MB)\n",
      "Trainable params: 109483009 (417.64 MB)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 05:29:37.494918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 20000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:26\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2025-08-18 05:29:37.571920: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/625 [>.............................] - ETA: 3:31:53 - loss: 0.7429 - binary_accuracy: 0.5010"
     ]
    }
   ],
   "source": [
    "history = train_evaluate(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91980420-8451-4869-b189-2b3693131ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcbcff-18d5-4448-b695-fd6bf3189c2f",
   "metadata": {},
   "source": [
    "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy. Based on the plots above, you should see model accuracy of around 78-80% which exceeds your business requirements target of greater than 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc3fed-aa4c-40b2-8c44-19be21ba4689",
   "metadata": {},
   "source": [
    "## Containerize your model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3905338-288b-4565-9abb-9053d7559315",
   "metadata": {},
   "source": [
    "Now that you trained and evaluated your model locally in a Vertex Notebook as part of an experimentation workflow, your next step is to train and deploy your model on Google Cloud's Vertex AI platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb61ec-cb3c-43bd-9d75-9d61ff52848e",
   "metadata": {},
   "source": [
    "To train your BERT classifier on Google Cloud, you will you will package your Python training scripts and write a Dockerfile that contains instructions on your ML model code, dependencies, and execution instructions. You will build your custom container with Cloud Build, whose instructions are specified in `cloudbuild.yaml` and publish your container to your Artifact Registry. This workflow gives you the opportunity to use the same container to run as part of a portable and scalable [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) workflow. \n",
    "\n",
    "\n",
    "You will walk through creating the following project structure for your ML mode code:\n",
    "```\n",
    "|--/bert-sentiment-classifier\n",
    "   |--/trainer\n",
    "      |--__init__.py\n",
    "      |--model.py\n",
    "      |--task.py\n",
    "   |--Dockerfile\n",
    "   |--cloudbuild.yaml\n",
    "   |--requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033e3c3-9dad-49d8-b53c-fd48113a8f90",
   "metadata": {},
   "source": [
    "### 1. Write a `model.py` training script\n",
    "\n",
    "First, you will tidy up your local TensorFlow model training code from above into a training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129184d-15ed-4ebe-bbdc-6c2687eb18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"bert-sentiment-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594afe7-b9e0-4957-9156-d2e595fde62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_DIR}/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from official.nlp import optimization\n",
    "\n",
    "DATA_URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "LOCAL_DATA_DIR = './tmp/data'\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def download_data(data_url, local_data_dir):\n",
    "    \"\"\"Download dataset.\n",
    "    Args:\n",
    "      data_url(str): Source data URL path.\n",
    "      local_data_dir(str): Local data download directory path.\n",
    "    Returns:\n",
    "      dataset_dir(str): Local unpacked data directory path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.makedirs(local_data_dir)\n",
    "    \n",
    "    dataset = tf.keras.utils.get_file(\n",
    "      fname='aclImdb_v1.tar.gz',\n",
    "      origin=data_url,\n",
    "      untar=True,\n",
    "      cache_dir=local_data_dir,\n",
    "      cache_subdir=\"\")\n",
    "    \n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    \n",
    "    # Remove unused folders to make it easier to load the data.\n",
    "    remove_dir = os.path.join(train_dir, 'unsup')\n",
    "    shutil.rmtree(remove_dir)\n",
    "    \n",
    "    return dataset_dir\n",
    "\n",
    "\n",
    "def load_datasets(dataset_dir, hparams):\n",
    "    \"\"\"Load pre-split tf.datasets.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      raw_train_ds(tf.dataset): Train split dataset (20k examples).\n",
    "      raw_val_ds(tf.dataset): Validation split dataset (5k examples).\n",
    "      raw_test_ds(tf.dataset): Test split dataset (25k examples).\n",
    "    \"\"\"    \n",
    "\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=hparams['seed'])    \n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=hparams['seed'])\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'test'),\n",
    "        batch_size=hparams['batch-size'])\n",
    "    \n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds\n",
    "\n",
    "\n",
    "def build_text_classifier(hparams, optimizer):\n",
    "    \"\"\"Define and compile a TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      model(tf.keras.Model): A compiled TensorFlow model.\n",
    "    \"\"\"\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    # TODO: Add a hub.KerasLayer for BERT text preprocessing using the hparams dict. \n",
    "    # Name the layer 'preprocessing' and store in the variable 'preprocessor'.\n",
    "    preprocessor = hub.KerasLayer(\n",
    "        hparams['preprocessing_url'], name='preprocessing'\n",
    "    )      \n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    # TODO: Add a trainable hub.KerasLayer for BERT text encoding using the hparams dict.\n",
    "    # Name the layer 'BERT_encoder' and store in the variable 'encoder'.\n",
    "    encoder = hub.KerasLayer(\n",
    "        hparams['encoder_url'], trainable=True, name='BERT_encoder'\n",
    "    )      \n",
    "    outputs = encoder(encoder_inputs)\n",
    "    # For the fine-tuning you are going to use the `pooled_output` array which represents \n",
    "    # each input sequence as a whole. The shape is [batch_size, H]. \n",
    "    # You can think of this as an embedding for the entire movie review.\n",
    "    classifier = outputs['pooled_output']\n",
    "    # Add dropout to prevent overfitting during model fine-tuning.\n",
    "    classifier = tf.keras.layers.Dropout(hparams['dropout'], name='dropout')(classifier)\n",
    "    classifier = tf.keras.layers.Dense(1, activation=None, name='classifier')(classifier)\n",
    "    model = tf.keras.Model(text_input, classifier, name='bert-sentiment-classifier')\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()    \n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_evaluate(hparams):\n",
    "    \"\"\"Train and evaluate TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    dataset_dir = download_data(data_url=DATA_URL, \n",
    "                                local_data_dir=LOCAL_DATA_DIR)\n",
    "    \n",
    "    raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(dataset_dir=dataset_dir,\n",
    "                                                          hparams=hparams)\n",
    "    \n",
    "    train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)     \n",
    "    \n",
    "    epochs = hparams['epochs']\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    n_train_steps = steps_per_epoch * epochs\n",
    "    n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "    \n",
    "    optimizer = optimization.create_optimizer(init_lr=hparams['initial-learning-rate'],\n",
    "                                              num_train_steps=n_train_steps,\n",
    "                                              num_warmup_steps=n_warmup_steps,\n",
    "                                              optimizer_type='adamw')    \n",
    "    \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_text_classifier(hparams=hparams, optimizer=optimizer)\n",
    "        logging.info(model.summary())\n",
    "        \n",
    "    history = model.fit(x=train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=epochs)  \n",
    "    \n",
    "    logging.info(\"Test accuracy: %s\", model.evaluate(test_ds))\n",
    "\n",
    "    # Export Keras model in TensorFlow SavedModel format.\n",
    "    model.save(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e16b936-d93a-4411-a494-aacda93b05f4",
   "metadata": {},
   "source": [
    "### 2. Write a `task.py` file as an entrypoint to your custom model container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17517e0b-a2ac-489a-bf03-357ace5d6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_DIR}/trainer/task.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Vertex custom container training args. These are set by Vertex AI during training but can also be overwritten.\n",
    "    parser.add_argument('--model-dir', dest='model-dir',\n",
    "                        default=os.environ['AIP_MODEL_DIR'], type=str, help='GCS URI for saving model artifacts.')\n",
    "\n",
    "    # Model training args.\n",
    "    parser.add_argument('--tfhub-bert-preprocessor', dest='tfhub-bert-preprocessor', \n",
    "                        default='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', type=str, help='TF-Hub URL.')\n",
    "    parser.add_argument('--tfhub-bert-encoder', dest='tfhub-bert-encoder', \n",
    "                        default='https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2', type=str, help='TF-Hub URL.')    \n",
    "    parser.add_argument('--initial-learning-rate', dest='initial-learning-rate', default=3e-5, type=float, help='Learning rate for optimizer.')\n",
    "    parser.add_argument('--epochs', dest='epochs', default=2, type=int, help='Training iterations.')    \n",
    "    parser.add_argument('--batch-size', dest='batch-size', default=32, type=int, help='Number of examples during each training iteration.')    \n",
    "    parser.add_argument('--dropout', dest='dropout', default=0.1, type=float, help='Float percentage of DNN nodes [0,1] to drop for regularization.')    \n",
    "    parser.add_argument('--seed', dest='seed', default=42, type=int, help='Random number generator seed to prevent overlap between train and val sets.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    model.train_evaluate(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a04a-5f15-4503-91e9-1acc4353fd08",
   "metadata": {},
   "source": [
    "### 3. Write a `Dockerfile` for your custom model container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b0320-a3c2-4fbd-96f0-48ca3b49d485",
   "metadata": {},
   "source": [
    "Third, you will write a `Dockerfile` that contains instructions to package your model code in `bert-sentiment-classifier` as well as specifies your model code's dependencies needed for execution together in a Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ede10-6372-4320-89d3-264d4d1b1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_DIR}/Dockerfile\n",
    "# Specifies base image and tag.\n",
    "# https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-11:latest\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /root\n",
    "\n",
    "# Copies the requirements.txt into the container to reduce network calls.\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Installs additional packages.\n",
    "RUN pip3 install -U -r requirements.txt\n",
    "\n",
    "# b/203105209 Removes unneeded file from TF2.5 CPU image for python_module CustomJob training. \n",
    "# Will be removed on subsequent public Vertex images.\n",
    "RUN rm -rf /var/sitecustomize/sitecustomize.py\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY . /trainer\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2974866-46f7-4f16-b6c0-9ea420ea6d73",
   "metadata": {},
   "source": [
    "### 4. Write a `requirements.txt` file to specify additional ML code dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d62327-31c6-4ae5-819c-f59fb16e58c3",
   "metadata": {},
   "source": [
    "These are additional dependencies for your model code not included in the pre-built Vertex TensorFlow images such as TF-Hub, TensorFlow AdamW optimizer, and TensorFlow Text needed for importing and working with pre-trained TensorFlow BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7619e1-fff9-4a47-90a8-3ba9b55e74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_DIR}/requirements.txt\n",
    "tf-models-official==2.15.0\n",
    "tensorflow-text==2.15.0\n",
    "tensorflow-hub==0.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81292584-7a08-4c92-a9ba-e3dbc7005130",
   "metadata": {},
   "source": [
    "## Use Cloud Build to build and submit your model container to Artifact Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47400c-aa7c-4929-a584-f5067bd682eb",
   "metadata": {},
   "source": [
    "Next, you will use [Cloud Build](https://cloud.google.com/build) to build and upload your custom TensorFlow model container to [Google Cloud Artifact Registry](https://cloud.google.com/artifact-registry). \n",
    "\n",
    "Cloud Build brings reusability and automation to your ML experimentation by enabling you to reliably build, test, and deploy your ML model code as part of a CI/CD workflow. Artifact Registry provides a centralized repository for you to store, manage, and secure your ML container images. This will allow you to securely share your ML work with others and reproduce experiment results.\n",
    "\n",
    "**Note**: the initial build and submit step will take about 16 minutes but Cloud Build is able to take advantage of caching for faster subsequent builds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c0d02-200f-4cc3-bdfd-ba96d233ecc4",
   "metadata": {},
   "source": [
    "### 1. Create Artifact Registry for custom container images \n",
    "\n",
    "**NOTE:** For any help to create the Artifact Registry, you can refer this [Documentation](https://cloud.google.com/sdk/gcloud/reference/artifacts/repositories/create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9918475-f6dc-4fa3-8249-47976e68f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_REGISTRY=\"bert-sentiment-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9566d-c6c4-48c8-b4f8-ad239e5ae349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a Docker Artifact Registry using the gcloud CLI. Note the required 'repository-format', 'location' and 'description' flags while creating the Artifact Registry.\n",
    "# Documentation link: https://cloud.google.com/sdk/gcloud/reference/artifacts/repositories/create\n",
    "gcloud artifacts repositories create my-docker-repo \\\n",
    "    --repository-format=docker \\\n",
    "    --location=us-central1 \\\n",
    "    --description=\"Docker repository for storing container images\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900832e-de90-4ba1-ba7d-7973a1de9cc1",
   "metadata": {},
   "source": [
    "### 2. Create `cloudbuild.yaml` instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b580619d-957c-409f-ac15-ccbc0bb79a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME=\"bert-sentiment-classifier\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REGISTRY}/{IMAGE_NAME}:{IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24790970-988e-4694-b8cd-a2d9d500c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbuild_yaml = f\"\"\"steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [ 'build', '-t', '{IMAGE_URI}', '.' ]\n",
    "images: \n",
    "- '{IMAGE_URI}'\"\"\"\n",
    "\n",
    "with open(f\"{MODEL_DIR}/cloudbuild.yaml\", \"w\") as fp:\n",
    "    fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14b9c6-c120-482d-b5ab-c6a4c53bb205",
   "metadata": {},
   "source": [
    "### 3. Build and submit your container image to Artifact Registry using Cloud Build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e154b1-e584-496c-97b4-14795f80928b",
   "metadata": {},
   "source": [
    "**Note:** your custom model container will take about 16 minutes initially to build and submit to your Artifact Registry. Artifact Registry is able to take advantage of caching so subsequent builds take about 10 minutes. For any help to submit a build, you can refer this [**documentation**](https://cloud.google.com/sdk/gcloud/reference/builds/submit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf0093-d66e-49c1-8a55-047020735e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use Cloud Build to build and submit your custom model container to your Artifact Registry.\n",
    "# Documentation link: https://cloud.google.com/sdk/gcloud/reference/builds/submit\n",
    "# Hint: make sure the config flag is pointed at `{MODEL_DIR}/cloudbuild.yaml` defined above and you include your model directory as {MODEL_DIR}. Also, add a timeout flag.\n",
    "\n",
    "gcloud builds submit {MODEL_DIR} \\\n",
    "  --tag us-central1-docker.pkg.dev/PROJECT_ID/my-docker-repo/bert-sentiment:latest \\\n",
    "  --config {MODEL_DIR}/cloudbuild.yaml \\\n",
    "  --timeout=30m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee35ac-ab83-472d-ab18-f622f3e3bc31",
   "metadata": {},
   "source": [
    "## Define a pipeline using the KFP V2 SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5556979-3583-44fd-86df-d30fab8d9464",
   "metadata": {},
   "source": [
    "To address your business requirements and get your higher performing model into production to deliver value faster, you will define a pipeline using the [**Kubeflow Pipelines (KFP) V2 SDK**](https://www.kubeflow.org/docs/components/pipelines/sdk/v2/v2-compatibility) to orchestrate the training and deployment of your model on [**Vertex Pipelines**](https://cloud.google.com/vertex-ai/docs/pipelines) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0e36b-3cb8-4660-bbb1-a5dcca49aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# google_cloud_pipeline_components includes pre-built KFP components for interfacing with Vertex AI services.\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a5ffc-ed1d-475d-8cc4-dd8ba765db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "USER = getpass.getuser()\n",
    "print(\"Notebook user:\", USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f7070-d6e5-47ab-a860-d6a7e7892164",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "DISPLAY_NAME = \"bert-sentiment-{}\".format(TIMESTAMP)\n",
    "GCS_BASE_OUTPUT_DIR= f\"{GCS_BUCKET}/{MODEL_DIR}-{TIMESTAMP}\"\n",
    "\n",
    "USER = \"\"  # TODO: change this to your name.\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(GCS_BUCKET, USER)\n",
    "\n",
    "print(f\"Model display name: {DISPLAY_NAME}\")\n",
    "print(f\"GCS dir for model training artifacts: {GCS_BASE_OUTPUT_DIR}\")\n",
    "print(f\"GCS dir for pipeline artifacts: {PIPELINE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aecd42-c969-4ce0-a49a-9150c45a91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-built Vertex model serving container for deployment.\n",
    "# https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "SERVING_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e8dbc-04b3-4193-87f5-984d2b98a2d0",
   "metadata": {},
   "source": [
    "The pipeline consists of three components:\n",
    "\n",
    "* `CustomContainerTrainingJobRunOp` [(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.CustomContainerTrainingJobRunOp): trains your custom model container using Vertex Training. This is the same as configuring a Vertex Custom Container Training Job using the Vertex Python SDK you covered in the Vertex AI: Qwik Start lab.\n",
    "\n",
    "*  `EndpointCreateOp` [(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.EndpointCreateOp): Creates a Google Cloud Vertex Endpoint resource that maps physical machine resources with your model to enable it to serve online predictions. Online predictions have low latency requirements; providing resources to the model in advance reduces latency. \n",
    "\n",
    "* `ModelDeployOp`[(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.ModelDeployOp): deploys your model to a Vertex Prediction Endpoint for online predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2181f3d-10cd-49c8-8e2f-e5c314940321",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"bert-sentiment-classification\", pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    location: str = REGION,\n",
    "    staging_bucket: str = GCS_BUCKET,\n",
    "    display_name: str = DISPLAY_NAME,    \n",
    "    container_uri: str = IMAGE_URI,\n",
    "    model_serving_container_image_uri: str = SERVING_IMAGE_URI,    \n",
    "    base_output_dir: str = GCS_BASE_OUTPUT_DIR,\n",
    "):\n",
    "    \n",
    "    #TODO: add and configure the pre-built KFP CustomContainerTrainingJobRunOp component using\n",
    "    # the remaining arguments of the pipeline constructor as defined in the starting of this cell. \n",
    "    # Hint: Refer to the component documentation link above if needed as well.\n",
    "    model_train_evaluate_op = gcc_aip.CustomContainerTrainingJobRunOp(\n",
    "        # Vertex AI Python SDK authentication parameters.        \n",
    "        project=project,\n",
    "        location=location,\n",
    "        staging_bucket=staging_bucket,\n",
    "        # WorkerPool arguments.\n",
    "        replica_count=1,\n",
    "        machine_type=\"e2-standard-4\",\n",
    "        # TODO: fill in the remaining arguments from the pipeline definition.\n",
    "\n",
    "    )    \n",
    "    \n",
    "    # Create a Vertex Endpoint resource in parallel with model training.\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        # Vertex AI Python SDK authentication parameters.\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=display_name\n",
    "    \n",
    "    )   \n",
    "    \n",
    "    # Deploy your model to the created Endpoint resource for online predictions.\n",
    "    model_deploy_op = gcc_aip.ModelDeployOp(\n",
    "        # Link to model training component through output model artifact.\n",
    "        model=model_train_evaluate_op.outputs[\"model\"],\n",
    "        # Link to the created Endpoint.\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        # Define prediction request routing. {\"0\": 100} indicates 100% of traffic \n",
    "        # to the ID of the current model being deployed.\n",
    "        traffic_split={\"0\": 100},\n",
    "        # WorkerPool arguments.        \n",
    "        dedicated_resources_machine_type=\"e2-standard-4\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783114fd-731b-4bad-bbe2-7a858e621fca",
   "metadata": {},
   "source": [
    "## Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28dac2-3721-4fe6-9e01-98745b0d1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77355b83-577b-4831-9862-91e08e974256",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"bert-sentiment-classification.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cda30-4046-4d29-abdd-501c243f5eee",
   "metadata": {},
   "source": [
    "## Run the pipeline on Vertex Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be420d-9d1d-4e8e-a08a-658fdfd60eb0",
   "metadata": {},
   "source": [
    "The `PipelineJob` is configured below and triggered through the `run()` method.\n",
    "\n",
    "**Note:** This pipeline run will take around **30-40** minutes to train and deploy your model. Follow along with the execution using the URL from the job output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276575d-c2ba-4d08-9a2a-b7583af27aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"bert-sentiment-classification\",\n",
    "    template_path=\"bert-sentiment-classification.json\",\n",
    "    parameter_values={\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"location\": REGION,\n",
    "        \"staging_bucket\": GCS_BUCKET,\n",
    "        \"display_name\": DISPLAY_NAME,        \n",
    "        \"container_uri\": IMAGE_URI,\n",
    "        \"model_serving_container_image_uri\": SERVING_IMAGE_URI,        \n",
    "        \"base_output_dir\": GCS_BASE_OUTPUT_DIR},\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab35e9-207c-49ea-8a27-6e6cddce8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a821a-a3bd-45bf-a9ea-aa18687218f6",
   "metadata": {},
   "source": [
    "## Query the deployed model using your Vertex endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd8366-d362-4537-ab30-21c21fce6846",
   "metadata": {},
   "source": [
    "Finally, you will retrieve the `Endpoint` deployed by the pipeline and use it to query your model for online predictions.\n",
    "\n",
    "Configure the `Endpoint()` function below with the following parameters:\n",
    "\n",
    "*  `endpoint_name`: A fully-qualified endpoint resource name or endpoint ID. Example: \"projects/123/locations/us-central1/endpoints/456\" or \"456\" when project and location are initialized or passed.\n",
    "*  `project_id`: GCP project.\n",
    "*  `location`: GCP region.\n",
    "\n",
    "Call `predict()` to return a prediction for a test review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80748b-8907-4ad6-8adb-d4c394752257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your deployed Endpoint name from your pipeline.\n",
    "ENDPOINT_NAME = vertexai.Endpoint.list()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c989d-1026-4f57-8dac-dafad01145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Generate online predictions using your Vertex Endpoint. \n",
    "#Hint: You need to add the following variables: endpoint_name, project, location, with their required values.\n",
    "\n",
    "endpoint = vertexai.Endpoint(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97759f45-e060-44ce-87fc-4d34c4b8cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a movie review to test your model e.g. \"The Dark Knight is the best Batman movie!\"\n",
    "test_review = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c008ce-90ad-4709-a24f-36b414c779e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use your Endpoint to return prediction for your 'test_review' using 'endpoint.predict()' method.\n",
    "prediction ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54751a3e-7b2a-4ab8-b642-6533df27de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4c68e-a937-44f8-b64a-cbe9e607cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a sigmoid function to compress your model output between 0 and 1. For binary classification, a threshold of 0.5 is typically applied\n",
    "# so if the output is >= 0.5 then the predicted sentiment is \"Positive\" and < 0.5 is a \"Negative\" prediction.\n",
    "print(tf.sigmoid(prediction.predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344e3eb-0a0e-4271-b815-e792d8c95b66",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80557132-f0cf-4f4d-be5d-2c58453bc6b6",
   "metadata": {},
   "source": [
    "Congratulations! You walked through a full experimentation, containerization, and MLOps workflow on Vertex AI. First, you built, trained, and evaluated a BERT sentiment classifier model in a Vertex Notebook. You then packaged your model code into a Docker container to train on Google Cloud's Vertex AI. Lastly, you defined and ran a Kubeflow Pipeline on Vertex Pipelines that trained and deployed your model container to a Vertex Endpoint that you queried for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6570ed8-a1ae-41e0-8a0b-9b63ca972d85",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2c9ee-e982-4b8b-91c3-02f313896c6c",
   "metadata": {},
   "source": [
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
